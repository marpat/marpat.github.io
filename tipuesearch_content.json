{"pages":[{"url":"pages/about.html","text":"I am a chemist by training, interested in organic chemistry, discovery of new medicines, and computer technology. I have enjoyed chemistry since my teenage and keep enjoying it today. Throughout my career, it was the scientific curiosity that led me into areas of organic chemistry , combinatorial chemistry , medicinal chemistry , peptide synthesis , drug design , and computational chemistry . Over the years, I have been intrigued by molecular structures and physicochemical properties of molecules. After mastering the basics of computational chemistry, I kept coming back to practical approaches to molecular models and molecular visualization. At one time, when immersed in a peculiar chemical puzzle, I run across the concept of Natural Bond Orbitals (NBO) . I found it extremely useful and I am learning and using it since. I enjoy writing simple applications and scripts to make processing and understanding results of NBO explorations easier. On the hobby side, I enjoy digital photography , color science, web design, and coding. An arsenal of my scripting and programming tools includes html, css, jQuery, PHP, Java, Python, and Matlab .","tags":"pages","title":"About"},{"url":"pages/contact.html","text":"The best way to contact me is by e-mail. # My contact e-mail is: email = ( \"chem g plus a t g ma il dot com\" ) . replace ( \" \" , \"\" ) Just kidding, click the button below. I'm on Google+ and you can also find me on twitter @mpatek_ . In case that you prefer mail encryption , my PGP/GPG fingerprint is : 8F4B 90A0 9F08 832A A4F9 518B 2814 15EF E5B6 1EE6 You can also just download it here . Show/Hide email","tags":"pages","title":"Contacts"},{"url":"jupyter-notebook-html-report.html","text":"Introduction While Jupyter notebook has a built-in facility for multiple output formats, its use depends on OS platform and requirements on the output file. Perhaps the most requested output is pdf format currently done in two-steps: html to latex to pdf 1 . Unfortunately for those working on Windows, Latex rendering requires installation of MiKTexT , Tex Live preferred by Jupyter and Latex editor, such as TeXstudio . The process of getting output similar to the original notebook is quite convoluted and impractical. An alternative solution is to print notebook directly to pdf format, assuming that one has installed the pdf writer (driver) on Windows. Print-to-pdf is the done by choosing the pdf as a printer. There are two issues that one may face should the desired report preserve color and be without the code cells . Let's start with an illustration of sample Jupyter notebook as rendered by Jupyter. Fig. 1. Rendering of the original Jupyter notebook. Alternatively, the complete Jupyter notebook is at this link: Sample_ipynb.ipynb First, we export the notebook as html file: Fig. 2. Exporting notebook as .html file. Color rendering Printing notebook directly (File -> Print Preview -> print (Ctrl+P)) to a printer device renders the notebook in black and white 2 . Fig. 3. B&W rendering of html file at the print. The culprit here is one line in the embedded style under the @media print section, specifically, color: #000 !important . This instruction overwrites default and custom colors, setting black-white as default print output. Fig. 4. css/style instructions to overwrite colors. This offending line is coming from the Bootstrap 3 .less template, which is part of the Jupyter notebook styling. There are three solutions: one is to edit out this line in the .less file and recompile the new default css file for notebooks. The second solution is to comment out the color: #000 !important line in the style.min.css file 3 and the third approach is to remove the same line from the embedded style section in exported html file. Last two approaches are demonstrated here. Editing min.css file: Locate the Jupyter default style sheet style.min.css in: minconda3\\Lib\\site-packages\\notebook\\static\\style\\style.min.css or minconda3\\envs\\your_environment\\Lib\\site-packages\\notebook\\static\\style\\style.min.css and search for phrase #000 !im . Comment out the line shown below and save: @ media print { *, * : before , * : after { background : transparent !important ; /*color: #000 !important;*/ box-shadow : none !important ; text-shadow : none !important ; } Editing rendered .html file file After creating html file in Jupyter notebook like so: File -> Download as -> HTML (html), comment out the same line as above and save. Code Cells Since notebooks are often used in education and collaborative projects, output of code cells has been often a desired feature. On the other hand, should the ultimate result be a report for the customer, code cells could be quite distracting. Fig. 5. Report with visible code cell. One way to suppress visibility of code cell is to use JQuery (javascript) in the separate Jupyter cell as per 4 , 5 : # Run (once) to allow nice html output as report (optional) \"\"\" Hide code cells in an IPython notebook or exported HTML using javascript. \"\"\" import IPython.core.display as di # This line will hide code by default when the notebook is exported as HTML di . display_html ( '<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area, .output_stderr\").toggle(); jQuery(\".prompt\").toggle();}});</script>' , raw = True ) CSS = \"\"\".input_area .output_stderr {height: 2.0em; overflow: hidden}\"\"\" # changes input_subarea width to 1 visible line HTML ( '<style>{}</style>' . format ( CSS )) # This line will add a button to toggle visibility of code blocks, for use with the HTML export version. di . display_html ( '''<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Click in rendered .html output only, toggles the code</button>''' , raw = True ) We can toggle visibility of the code in html report displayed in the browser. To remove the code completely, one can add a Jinja2 template into nbconvert-templates directory. For example, create file report.tpl with the following content and place it into the html directory under template folder 5 . {%- extends 'full.tpl' -%} {%-block input_group scoped-%} {%- if 'jupyter:' and cell.cell_type == 'code'-%} {%- endif -%} {%-endblock input_group -%} The full default path to your Jupyter templates is: # In my case C:/miniconda3/envs/main/Lib/site-packages/nbconvert/templates/html # or in general your_Python_path/Lib/site-packages/nbconvert/templates/html Then add the following cell into Jupyter notebook: # Create output with template. Input is removed from nbconvert import HTMLExporter import codecs import os stamp = datetime . today () . strftime ( \"%m_ %d _%Y\" ) exporter = HTMLExporter ( template_file = 'report.tpl' ) output , resources = exporter . from_filename ( 'Sample_ipynb.ipynb' ) new_fnm = stamp + '_sample_report.html' codecs . open ( new_fnm , 'w' , encoding = 'utf-8' ) . write ( output ) In this particular case, a file called sample_report.html with prepended date-stamp will be created in your notebook directory. Now, for the completeness, we can add one more cell with code to remove color: #000 !important line from the html file: # Delete 'print B&W' instruction in css/style section program = open ( new_fnm , \"r\" ) lines = program . readlines () program . close () f = open ( stamp + '_sample_report_print.html' , \"w\" ) for line in lines : if not line . startswith ( ' color: #000 !important' ): f . write ( line ) f . close () os . remove ( new_fnm ) Here is the rendered version of the notebook just before printing with link to complete html file: sample_report_print Fig. 6. Final report at the print stage. Other ways to create reports To further customize the appearance of the report, html file without the code cells and stripped of the color: #000 !important line, the file is first rendered in the browser, its content selected (ctrl+a, ctrl+c) and pasted into new MS Word (Google Docs) document. Style of paragraphs and tables can be tweaked. At this point, we should be very close to the final report style with a much improved visual appeal. References: Jessica Yung, Converting Jupyter Notebooks to PDFs . ↩ GitHub, Color printing should be an option ↩ Ilho Song, Mid the Gap ↩ Max Masnick, how-to-hide-code-from-cells-in-ipython-notebook-visualized-with-nbviewer ↩ Jörg Dietrich, Blogging with IPython and Collapsible Input Cells ↩ ↩ Gregory Ashton, Ipython NBConvert latex template to hide code ↩","tags":"Jupyter","title":"Create html Report from Jupyter Notebook on Windows"},{"url":"Natural-Dipole-Analysis.html","text":"Blogging with IPython Notebook IPython Notebook ( Jupyter notebook ) is a web-based interactive computing platform that combines live code, equations, text, images, and other media. These documents provide a complete record of computation approach that can be shared with others. Also, the IPython Notebook is not only a tool for scientific research and data analysis, but also a great tool for teaching. Technically, Notebook launches a web-based shell to an IPython session that has handy features, like the ability to save, edit, and delete lines of code. The code is organized into cells of Python, text, or Markdown. One can move the cells around, develop code interactively with documentation and notes, display objects that a browser can render (e.g., images, HTML, videos) and to share the whole notebook for a collaborative work. To demonstrate the utility and benefits of using IPython Notebook, the notebook decribed in this blog discusses Python code to analyse Natural dipole moment and its components. Steps of installing iPython notebook on Windows (as a part of Anaconda package) are described in blog \"Analyzing NBO Results with IPython Notebook\" This notebook discusses Python code to analyse Natural dipole moment of planar molecules. In the \" DIPOLE MOMENT ANALYSIS \" section, the NBO output file (.nbo, .out) contains individual x,y,z-components and length of the total molecular dipole moment. Each of the entries is decomposed into individual NLMO and NBO bond contributions. On the example of formamide, we are going to extract those lines and build a vector (NLMO) representation of the total molecular dipole. Similar method using Java-based KNIME platform is described here . Details of the formamide analysis can be found in the excellent book of Weinhold and Landis: Weinhold, F. and Landis, C.R. in Discovering Chemistry with Natural Bond Orbitals , pp. 147-152. Planar geometry of formamide Electric Dipole Â Electric dipole moment is the most fundamental quantity related to the charge distribution in a molecule. It reflects the degree to which positive and negative charge is distributed relative to one another. Dipole moment is a vector quantity characterized by its scalar magnitude, sign, and direction. Accordingly, the dipole can be described by its vector μ directed from the negative to the positive charge. Magnitude of the dipole moment is defined as: $$\\mu = |q|*R,$$ where q is charge and R is the displacement vector pointing from the negative to positive charge. The net dipole moment of a molecule can be conceptually described as a vector sum of the individual moments. This is what we will attempt to do in the following cells. Styling and Imports Â First the custom styling. File *.css inserts contents of custom .css file into the header of the notebook's HTML file. Other variants of .css files are in the ./css directory and differ only in color decoration of iPython notebook cells. This step is optional and the if ... else statement can be commented out. In [1]: %% capture # suppress output; remove %% capture for debugging # to (de)activate line numbering pres Esc while in the cell # followed by l (lower L) '''Sanity check since we are changing directories and *.css file path would be incorrect after cell re-run''' from IPython.core.display import HTML import string,sys,os,os.path,re css_file = './css/blog.css' if os.path.isfile(css_file): css_file else: %cd .. HTML(open(css_file, \"r\").read()) csv to Dataframe Â In the next step, coordinates of NLMO dipoles are read from *.csv file. This file was generated earlier using the KNIME \"Dipole_v2/3\" workflow . Alternatively, iPython notebook ReadNboDip.ipynb at this Github repository creates the identical input file. \"Plain\" Python script ( ReadNboDip.py ) that parses NBO output files for the same Dipole moment summary can be downloaded from this Github repository . In this example, this file is available from the ./dipole directory. In [3]: %% capture # Step into the directory of input .csv files using the magic %cd # Make sure that we are not already in the 'dipoles' dir from the previous run if os.path.isdir('dipoles'): %cd dipoles else: %cd .. %cd dipoles First, a row of arbitrary values (zeroes) is inserted at the top of dataframe df (line 15; press Esc+l (lower L)) and the table values are assigned int, float, or string types, respectively. In [ ]: # Input file can be generated in ReadNboDip.ipynb notebook infile = 'form_dip.csv' # in directory ./dipoles # Save the file path, name and extension fullpath = os . path . abspath ( infile ) path , file = os . path . split ( fullpath ) basename , extension = os . path . splitext ( infile ) # Create Pandas dataframe from the *.csv file df = pd . read_csv ( infile ) # fix datatype for columns df . convert_objects ( convert_numeric = True ) . dtypes # Prepare first blank row with XYZ=0 to set the point of vector origin # set the first row to zeroes rowex = df . loc [[ 0 ]] # Get dataframe column headers headers = df . columns . values . tolist () # Fix the data types for item in headers : if df . dtypes [ item ] == 'float64' : rowex [ item ] = 0. elif df . dtypes [ item ] == 'int64' : rowex [ item ] = 0 else : rowex [ item ] = '' row0 = rowex In [5]: # Reassemble data table placing row0 at the top, followed by the rest df2 = pd . concat ([ row0 , df ]) . reset_index () . ix [::] # print df2 In [6]: \"\"\" Identify which column (coordinate) has constant values (orthogonal to the molecular plane). \"\"\" # Prepare stds of absolute values for each x,y,z column # Smallest stds indicate constant dimension perpendicular to 2D plane C1 = df2 [ \"X\" ] . abs () C1std = C1 . std () C2 = df2 [ \"Y\" ] . abs () C2std = C2 . std () C3 = df2 [ \"Z\" ] . abs () C3std = C3 . std () # print \"stds are: %.3f %.3f %.3f\" % (C1std, C2std, C3std) In [7]: '''Assign X,Y coordinates only, Z=0. Any of the X,Y,Z can be constant or zero 0 (which one may change every time). Remap coordinates arbitrarily to X,Y with Z=[const] ''' def coord_headers ( C1std , C2std , C3std ): if C1std > 0.1 and C2std > 0.1 > C3std : df2 [ 'newX' ] = df2 [ \"X\" ] df2 [ 'newY' ] = df2 [ \"Y\" ] elif C1std > 0.1 > C2std and C3std > 0.1 : df2 [ 'newX' ] = df2 [ \"X\" ] df2 [ 'newY' ] = df2 [ \"Z\" ] elif C1std < 0.1 < C2std and C3std > 0.1 : df2 [ 'newX' ] = df2 [ \"Y\" ] df2 [ 'newY' ] = df2 [ \"Z\" ] else : df2 [ 'newX' ] = df2 [ \"X\" ] df2 [ 'newY' ] = df2 [ \"Y\" ] In [8]: # Append columns newX,newY to df2 (values are often same as the original X,Y) # Plane defined coord_headers ( C1std , C2std , C3std ) # Remove rows with CR (core) orbitals and reindex the dataframe df2 = df2 [ ~ df2 [ 'Type' ] . str . contains ( \"CR\" )] # Copy dataframe for the intermediate output df2b1 = df2 . reset_index () . ix [::] # Comment off if re-running the cell HTML ( df2b1 . to_html ( classes = 'grid' , escape = False )) # table styling requires package qgrid http://nbviewer.ipython.org/github/quantopian/qgrid/ # blob/master/qgrid_demo.ipynb Out[8]: level_0 index NLMO Type X Y Z Tot_Dip newX newY 0 0 0 0 0.00 0 0.00 0.00 0.00 0.00 1 4 3 4 LP ( 1) N 1 -0.20 0 -1.64 1.65 -0.20 -1.64 2 5 4 5 LP ( 1) O 3 -2.37 0 -1.64 2.88 -2.37 -1.64 3 6 5 6 LP ( 2) O 3 0.89 0 0.75 1.16 0.89 0.75 4 7 6 7 BD ( 1) N 1- C 2 0.02 0 0.85 0.85 0.02 0.85 5 8 7 8 BD ( 1) N 1- H 4 -0.68 0 0.47 0.82 -0.68 0.47 6 9 8 9 BD ( 1) N 1- H 5 0.75 0 0.46 0.88 0.75 0.46 7 10 9 10 BD ( 1) C 2- O 3 -1.90 0 -1.44 2.38 -1.90 -1.44 8 11 10 11 BD ( 2) C 2- O 3 -0.67 0 -0.46 0.81 -0.67 -0.46 9 12 11 12 BD ( 1) C 2- H 6 1.72 0 -0.58 1.82 1.72 -0.58 Table 1 . Current df2 with new columns for consolidated X, Y coordinates. First Plot Â Now, to have dipole vectors continue from one to another (as opposed to all starting at the zero), we have to transpose coordinates in a way that the origin of new vector starts at the end of the previous vector. In Python, use the function cumsum() . Let's try to build continuous vector graph from the original dataframe df2 . This is equivalent to a vector decomposition. **The following cell is just a test case** (can be removed later). It generates plot of Table 1 as continuing vector segments. You can skip it and go to section \"Cleaning up the Vector Path\" . In [9]: # Test area running off the branch df2b1 # Translate coordinates from X,Y,Z=0,0,0 to assure vector continuity df2b1 [ 'newXa' ] = df2b1 . newX . cumsum () df2b1 [ 'newYa' ] = df2b1 . newY . cumsum () df3b = df2b1 # print df3b # Calculate total dipole (compare with column Tot_Dip) lastX = df3b . tail ( 1 ) . newXa # row and value lastX = lastX . tolist ()[ 0 ] # value only lastY = df3b . tail ( 1 ) . newYa lastY = lastY . tolist ()[ 0 ] total_dipole = sqrt ( np . power ( lastX , 2 ) + np . power ( lastY , 2 )) total_dipole = round ( total_dipole , 2 ) # Calc geometrical center of the vector polygon cenX = df3b [ 'newXa' ] . mean () cenY = df3b [ 'newYa' ] . mean () x = df3b . newXa y = df3b . newYa # Plot # Set rectangular plot dimensions to keep lengths proportional xlow = x . min () xhigh = x . max () ylow = y . min () yhigh = y . max () def lst_sort ( list ): ''' Sort list of floats by values. :type list: list of floats :param list: max and min x,y-coordinates :rtype: list of floats :return: sorted list of floats ''' abslist = [] for item in list : abslist . append ( item ) return sorted ( abslist ) margins = lst_sort ([ xlow , ylow , xhigh , yhigh ]) plt . figure () # To generate multiple distinct plots. plt . suptitle ( 'Dipole Moments (D)' ) ax = [] xmin = margins [ 0 ] - 1 #x.min()-1 xmax = margins [ 3 ] + 1 ymin = margins [ 0 ] - 1 ymax = margins [ 3 ] + 1 plt . ylabel ( 'Y' ) plt . xlabel ( 'X' ) plt . grid ( True ) plt . xlim ( xmin , xmax ) plt . ylim ( ymin , ymax ) color = 'blue' plt . scatter ( df3b . newXa , df3b . newYa , s = 80 , c = color , label = 'NLMOs' ) for j , txt in enumerate ( df3b [ 'NLMO' ]): plt . annotate ( txt , ( x [ j ] + 0.1 , y [ j ] + 0.3 )) ax = gca () ax . add_patch ( FancyArrowPatch (( 0 , 0 ),( lastX , lastY ), arrowstyle = '->' , mutation_scale = 20 , color = 'red' )) for k in range ( 1 , len ( x )): ax . add_patch ( FancyArrowPatch (( x [ k ], y [ k ]),( x [ k - 1 ], y [ k - 1 ]), arrowstyle = '<-' , mutation_scale = 20 , color = 'blue' )) plt . annotate ( total_dipole , xy = ( lastX / 2 * 0.9 , lastY / 2 * 1.1 ), color = 'red' , xycoords = 'data' , textcoords = 'offset points' ) plt . annotate ( \"+\" , xy = ( cenX , cenY ), color = 'red' , xycoords = 'data' , textcoords = 'offset points' ) C:\\Anaconda\\envs\\notebook\\lib\\site-packages\\matplotlib\\text.py:1857: UserWarning: You have used the `textcoords` kwarg, but not the `xytext` kwarg. This can lead to surprising results. warnings.warn(\"You have used the `textcoords` kwarg, but not \" Out[9]: <matplotlib.text.Annotation at 0x776b050> Cleaning up the Vector Path Resulting plot is rather cluttered and thus we will need to arrange dipoles in some way to get a more interpretable view. Since most molecules have center of the coordinate system placed somewhere at the center of the molecule, sorting dipole coordinates by xy-quadrant in which the dipole origin resides is a sensible approach. The following cartoon indicates how such quadrants are defined. We will write a function that assigns each row an arbitrary quadrant depending on the signs of coordinates x and y . To further arrange directions of lines in each quadrant, we will include another function that calculates slope of the line and we will sort by the quadrant (rank) and the slope . In [10]: # Function to rank XY-points into quadrants 0-3 def xyrank ( a , b , c , d , e , f ): ''' Assign qudrant value 1,2,3,4. :type inputs: floats and str :param inputs: X, Y, Q(1), Q(2), Q(3), Q(4) :rtype: str :return: quadrant number as str ''' if a > 0 and b > 0 : # [Q1] return c elif a > 0 > b : # [Q2] return d elif a < 0 and b < 0 : # [Q3] return e else : # [Q4] 1 a>0, b<0 return f # Function to calculate slope def slope ( a , b ): if a != 0 : slope = ( 1.0 * b / a ) # expects float return slope else : slope = 0 # for a = zero, set slope arbitrarily to 0 return slope Unfortunately, it is not obvious which sequence of quadrants will lead to the least cluttered dipole diagram. To make sure that we test all possibilities, we will evaluate all permutations of four quadrants, that is, 4! = 4 x 3 x 2 x 1 = 24 For each trial, we record an array of quadrants and standard deviation of distances of all vector origins from the graph origin (geometric center). Small stds should indicate even distribution of vectors around the origin (circle, ellipsoid, symmetrical polygon?). Standard deviation of distances together with the sequence of quadrants appear at the top of each plot. As we will see later, lowest stds are not necesarilly indicative of the \"clean\" graph shape. By no means the resulting vector plots indicate atom connectivity! It is the relative direction of dipole vectors that helps us to assess the importance and internal balance of NLMO orbitals within the molecule. In [11]: # Get the list of quadrant permutations # Four quadrants of a XY plot lst = [ 0 , 1 , 2 , 3 ] set ( list ( lst )) # Creates a set import itertools permlist = set ( itertools . permutations ( lst )) permlist = list ( permlist ) # Get permutation set into a list. Plot Survey Â For each set of qudrants, the code below will sort the dataframe by the quadrant and slope. The corresponding plot will be created and saved as .png image. Quadrant sequence is part of the filename. In [12]: %% capture # remove %%capture magic to see the plot and output # Iterate through the list of all quadrants global captarr captarr = [] captperm = [] for i in range(len(permlist)): # Apply function to the table values in each row; make a copy first df21 = df2.copy() df21[\"xyRank\"] = df2.apply( lambda row: xyrank(row['newX'], row['newY'], permlist[i][0], permlist[i][1], permlist[i][2], permlist[i][3]), axis=1) # Apply function to table values in a row df21[\"slope\"] = df21.apply(lambda row: slope(row['newX'], row['newY']), axis=1) toprow = df21[:1] # row with zero dipole # Directly change rank of the first row in the dataframe toprow.xyRank[0] = 4 # Isolate remaining data into rest (drop) rest1 = df21.drop(df21.index[[0, 0]]) # sort rest1 by xyRank, then by slope - descending df3 = rest1.sort_index(by=['xyRank', 'slope'], ascending=[False, False]) # Put it back df3 = pd.concat([toprow, df3]).reset_index().ix[::] df3 = df3.sort_index(by=['xyRank', 'slope'], ascending=[False, False]) # Translate coordinates from xyz=0,0,0 df3['newXa'] = df3.newX.cumsum() df3['newYa'] = df3.newY.cumsum() # Calculate total dipole lastX = df3.tail(1).newXa # row and value lastX = lastX.tolist()[0] # value only lastY = df3.tail(1).newYa lastY = lastY.tolist()[0] total_dipole = sqrt(np.power(lastX, 2) + np.power(lastY, 2)) total_dipole = round(total_dipole, 2) # Calc distances of x,y and assess even distribution of points # around the geom center cenX = df3['newXa'].mean() cenY = df3['newYa'].mean() distX = abs(cenX - df3.newXa) distY = abs(cenY - df3.newYa) # distance from centroid distXY = np.sqrt(distX * distX + distY * distY) diststd = distXY.std() captarr.append(round(diststd, 1)) captperm.append(permlist[i]) print \"++++++++++ Rank list is : \", permlist[i], \"; \\ std of distances is:\", round(diststd, 2) # Plot plt.figure() # To generate multiple distinct plots. plt.suptitle('Dipole Moments (D)') ax = [] x = df3.newXa y = df3.newYa xmin = x.min() - 1 xmax = x.max() + 1 ymin = y.min() - 1 ymax = y.max() + 1 plt.ylabel('Y') plt.xlabel('X') plt.grid(True) plt.xlim(xmin, xmax) plt.ylim(ymin, ymax) color = 'blue' plt.scatter(df3.newXa, df3.newYa, s=80, c=color, label='NLMOs') # plt.plot(df3.newXa, df3.newYa, c=color) # plt.legend(loc=1,borderaxespad=0.) for j, txt in enumerate(df3['NLMO']): plt.annotate(txt, (x[j] + 0.1, y[j] + 0.3)) ax = gca() ax.add_patch(FancyArrowPatch((0, 0), (lastX, lastY), arrowstyle='->', \\ mutation_scale=20, color='red')) for k in range(1, len(x)): ax.add_patch( FancyArrowPatch((x[k], y[k]), (x[k - 1], y[k - 1]), arrowstyle='<-', \\ mutation_scale=20, color='blue')) plt.annotate(total_dipole, xy=(lastX / 2 * 0.9, lastY / 2 * 1.1), color='red', xycoords='data', textcoords='offset points') plt.annotate(round(diststd, 2), xy=(df3['newXa'].min() + 1.5, df3['newYa'].max() + 0.3), color='green', xycoords='data', textcoords='offset points') plt.annotate((permlist[i]), # asumX, asumY, xy=(xmin + 0.2, ymax - 0.7), color='black', xycoords='data', textcoords='offset points') plt.annotate(\"+\", xy=(cenX, cenY), color='red', xycoords='data', textcoords='offset points') # plt.show() f_perm = str(permlist[i]).replace(\"(\", \"_\") f_perm = f_perm.replace(\")\", \"_\") f_perm = f_perm.replace(\",\",\"\") f_perm = f_perm.replace(\" \",\"\") pic = basename + f_perm + '.png' try: plt.savefig(pic, ext='png', format='png', dpi=100) except IOError: print \"Error: can\\'t find the file or read data\" Rank Quadrants STD distance ++++++++++ Rank list is : (1, 0, 3, 2) std of distances is: 1.23 ++++++++++ Rank list is : (3, 0, 2, 1) std of distances is: 1.08 ++++++++++ Rank list is : (3, 1, 2, 0) std of distances is: 1.09 ++++++++++ Rank list is : (1, 2, 3, 0) std of distances is: 1.34 ++++++++++ Rank list is : (2, 0, 1, 3) std of distances is: 1.26 ++++++++++ Rank list is : (3, 0, 1, 2) std of distances is: 1.31 ++++++++++ Rank list is : (0, 1, 3, 2) std of distances is: 1.4 ++++++++++ Rank list is : (0, 2, 1, 3) std of distances is: 1.02 ++++++++++ Rank list is : (3, 2, 1, 0) std of distances is: 1.11 ++++++++++ Rank list is : (1, 0, 2, 3) std of distances is: 1.28 ++++++++++ Rank list is : (1, 3, 2, 0) std of distances is: 1.22 ++++++++++ Rank list is : (0, 3, 2, 1) std of distances is: 1.17 ++++++++++ Rank list is : (3, 1, 0, 2) std of distances is: 1.26 ++++++++++ Rank list is : (0, 1, 2, 3) std of distances is: 1.38 ++++++++++ Rank list is : (2, 0, 3, 1) std of distances is: 1.3 ++++++++++ Rank list is : (3, 2, 0, 1) std of distances is: 1.26 ++++++++++ Rank list is : (0, 2, 3, 1) std of distances is: 1.33 ++++++++++ Rank list is : (0, 3, 1, 2) std of distances is: 1.1 ++++++++++ Rank list is : (1, 3, 0, 2) std of distances is: 1.32 ++++++++++ Rank list is : (2, 3, 0, 1) std of distances is: 1.35 ++++++++++ Rank list is : (1, 2, 0, 3) std of distances is: 1.27 ++++++++++ Rank list is : (2, 1, 0, 3) std of distances is: 1.24 ++++++++++ Rank list is : (2, 3, 1, 0) std of distances is: 1.2 ++++++++++ Rank list is : (2, 1, 3, 0) std of distances is: 1.28 In [14]: # Sort by distance stds and retrieve the first three results data = zip ( captperm , captarr ) sor = sorted ( data , key = lambda tup : tup [ 1 ]) print sor [ 0 : 3 ] [((0, 2, 1, 3), 1.0), ((3, 0, 2, 1), 1.1), ((3, 1, 2, 0), 1.1)] Inspect graphs above and note the quadrant sequence of the best looking graph. As indicated earlier, it is not the graph with lowest std value. Final Plot Â To make the final plot, enter the quadrant sequence of the best looking plot above (0,3,2,1) and replace the sequence in variable quad . The plot image will be saved in directory ./dipole. Enter the quadrant sequence (to line 2) and re-run the last part to get the graph. In [15]: # Enter the best sequence of quadrants quad = [ 0 , 3 , 2 , 1 ] # original sequence 0,3,2,1 or 1,3,2,0 df21 = df2 . copy () df21 [ \"xyRank\" ] = df2 . apply ( lambda row : xyrank ( row [ 'newX' ], row [ 'newY' ], \\ quad [ 0 ], quad [ 1 ], quad [ 2 ], quad [ 3 ]), axis = 1 ) # Apply function to table values in a row df21 [ \"slope\" ] = df21 . apply ( lambda row : slope ( row [ 'newX' ], row [ 'newY' ]), axis = 1 ) toprow = df21 [: 1 ] # row with zero dipole # Directly change cell rank in dataframe toprow . xyRank [ 0 ] = 4 # Isolate remaining data into rest (drop) rest1 = df21 . drop ( df21 . index [[ 0 , 0 ]]) # sort rest1 by xyRank, then by slope - descending df3 = rest1 . sort_index ( by = [ 'xyRank' , 'slope' ], ascending = [ False , False ]) # Put it back df3 = pd . concat ([ toprow , df3 ]) . reset_index () . ix [::] df3 = df3 . sort_index ( by = [ 'xyRank' , 'slope' ], ascending = [ False , False ]) # Translate coordinates from xyz=0,0,0 df3 [ 'newXa' ] = df3 . newX . cumsum () df3 [ 'newYa' ] = df3 . newY . cumsum () # print df3 # works OK # Calculate total dipole lastX = df3 . tail ( 1 ) . newXa # row and value lastX = lastX . tolist ()[ 0 ] # value only lastY = df3 . tail ( 1 ) . newYa lastY = lastY . tolist ()[ 0 ] total_dipole = sqrt ( np . power ( lastX , 2 ) + np . power ( lastY , 2 )) total_dipole = round ( total_dipole , 2 ) # Calc distances of x,y and assess fit to a circle cenX = df3 [ 'newXa' ] . mean () cenY = df3 [ 'newYa' ] . mean () distX = abs ( cenX - df3 . newXa ) distY = abs ( cenY - df3 . newYa ) # distance from centroid distXY = np . sqrt ( distX * distX + distY * distY ) diststd = distXY . std () x = df3 . newXa y = df3 . newYa # Set rectangular plot dimensions to keep lengths proportional xlow = x . min () xhigh = x . max () ylow = y . min () yhigh = y . max () def lst_sort ( list ): ''' Sort list of floats by values. :type list: list of floats :param list: max and min x,y-coordinates :rtype: list of floats :return: sorted list of floats ''' abslist = [] for item in list : abslist . append ( item ) return sorted ( abslist ) margins = lst_sort ([ xlow , ylow , xhigh , yhigh ]) # Plot plt . figure () # To generate multiple distinct plots. plt . suptitle ( 'Dipole Moments (D)' ) ax = [] xmin = margins [ 0 ] - 1 xmax = margins [ 3 ] + 1 ymin = margins [ 0 ] - 1 ymax = margins [ 3 ] + 1 plt . ylabel ( 'Y' ) plt . xlabel ( 'X' ) plt . grid ( True ) plt . xlim ( xmin , xmax ) plt . ylim ( ymin , ymax ) color = 'blue' plt . scatter ( df3 . newXa , df3 . newYa , s = 80 , c = color , label = 'NLMOs' ) # plt.plot(df3.newXa, df3.newYa, c=color) # plt.legend(loc=1,borderaxespad=0.) for j , txt in enumerate ( df3 [ 'NLMO' ]): plt . annotate ( txt , ( x [ j ] + 0.1 , y [ j ] + 0.3 )) ax = gca () ax . add_patch ( FancyArrowPatch (( 0 , 0 ),( lastX , lastY ), arrowstyle = '->' , mutation_scale = 20 , \\ color = 'red' )) for k in range ( 1 , len ( x )): ax . add_patch ( FancyArrowPatch (( x [ k ], y [ k ]),( x [ k - 1 ], y [ k - 1 ]), arrowstyle = '<-' , \\ mutation_scale = 20 , color = 'blue' )) plt . annotate ( total_dipole , xy = ( lastX / 2 * 0.9 , lastY / 2 * 1.1 ), color = 'red' , xycoords = 'data' , textcoords = 'offset points' ) plt . annotate (( quad ), # asumX, asumY, xy = ( xmin + 0.4 , ymax - 0.6 ), color = 'black' , xycoords = 'data' , textcoords = 'offset points' ) plt . annotate ( \"+\" , xy = ( cenX , cenY ), color = 'red' , xycoords = 'data' , textcoords = 'offset points' ) df3 . drop ( 'level_0' , axis = 1 , inplace = True ) df3 . drop ( 'index' , axis = 1 , inplace = True ) HTML ( df3 . to_html ( classes = 'grid' , escape = False )) Out[15]: NLMO Type X Y Z Tot_Dip newX newY xyRank slope newXa newYa 0 0 0.00 0 0.00 0.00 0.00 0.00 4 0.000000 0.00 0.00 1 12 BD ( 1) C 2- H 6 1.72 0 -0.58 1.82 1.72 -0.58 3 -0.337209 1.72 -0.58 2 4 LP ( 1) N 1 -0.20 0 -1.64 1.65 -0.20 -1.64 2 8.200000 1.52 -2.22 3 10 BD ( 1) C 2- O 3 -1.90 0 -1.44 2.38 -1.90 -1.44 2 0.757895 -0.38 -3.66 4 5 LP ( 1) O 3 -2.37 0 -1.64 2.88 -2.37 -1.64 2 0.691983 -2.75 -5.30 5 11 BD ( 2) C 2- O 3 -0.67 0 -0.46 0.81 -0.67 -0.46 2 0.686567 -3.42 -5.76 6 8 BD ( 1) N 1- H 4 -0.68 0 0.47 0.82 -0.68 0.47 1 -0.691176 -4.10 -5.29 7 7 BD ( 1) N 1- C 2 0.02 0 0.85 0.85 0.02 0.85 0 42.500000 -4.08 -4.44 8 6 LP ( 2) O 3 0.89 0 0.75 1.16 0.89 0.75 0 0.842697 -3.19 -3.69 9 9 BD ( 1) N 1- H 5 0.75 0 0.46 0.88 0.75 0.46 0 0.613333 -2.44 -3.23 An alternative and acceptable vector decomposition is shown in Figure 4 . Figure 4 Alternative vector decomposition. This concludes the analysis of NLMO dipole moment data from the NBO output file. Several vector paths composed of partial formamide dipoles were created and saved as images. Next step will be analysis of partial NLMO dipoles in terms of bonds and lone pair contributions. The complete Notebook Dipoles_quad_all_Jupyter.ipynb and accompanying files are available at the GitHub .","tags":"NBO","title":"Natural Dipole Analysis"},{"url":"python-anaconda-and-pelican-on-windows.html","text":"Introduction With so many blogs and descriptive how-to's out there 1 , 2 , 3 , 4 , 5 , one may be wondering as to why another post on Pelican static site generator. The purpose of this blog is to document building a static web site in Windows environment with Anaconda Python distribution. This tutorial assumes very little, so we will cover each step in a little more details. Chances are that you have already heard about the the Python-powered micro web frameworks, static page generators, and even about Pelican , Nikola , or Flask . If not, this blog 4 has a nice introduction. Pelican is a static web page generator that delivers web pages to the user exactly as they are stored on the server. There is no user-interaction possible once the pages are rendered. In contrast, dynamic web pages are generated and updated by a web application. Pelican is written in Python and it is platform independent. Requirements Before we can get started, we'll need to have a functioning installation of Python , and of course, Pelican . The following are the minimum requirements: Python 2.7.x or Python 3 (Python 2.7 is still preferred on Windows due to several dependencies, such as 'pycrypto', not available for Py3.6) Pelican package Text editor (e.g., Notepad++ , Markdown Pad , Sublime Text ) Web server for the web hosting Python First, we need a Python installation. I recommend Anaconda or Miniconda Python Distribution from the Continuum Analytics . Anaconda and Miniconda are free and the former comes with many pre-installed Python packages and libraries such as Pandas, NumPy, matplotlib, and others. However, the default packages do not include Pelican site generator. If you already have Python installed, skip to the section Virtual Environment . To get Anaconda/Miniconda installed under the Windows, download the latest Anaconda and install the executable. This tutorial is using Anaconda although steps with Miniconda are the same. The typical path to install Anaconda on Windows is: C:\\Anaconda . For more details on installation steps, see this YouTube video . When installation completes, append the following string (without the quotes) into your system PATH : \" C:\\Anaconda;C:\\Anaconda\\Lib;C:\\Anaconda\\DLLs;C:\\Anaconda\\Lib\\lib-tk;C:\\Anaconda\\Scripts; \" To access the PATH variable, right-click on Computer ⇒ Advanced system settings ⇒ Advance tab ⇒ Environment Variables ⇒ System variables ⇒ Path. _Note that the latest Anaconda/Miniconda installation binaries set correct path **if checked** during install_. To check that Anaconda has installed successfully, launch the Windows command shell (cmd.exe) and execute the command: conda info -- all A typical output follows: Current conda install: platform : win-32 conda version : 3.11.0-dirty conda-build version : 1.2.0 python version : 2.7.6.final.0 requests version : 2.7.0 root environment : C:\\Anaconda (writable) default environment : C:\\Anaconda envs directories : C:\\Anaconda\\envs package cache : C:\\Anaconda\\pkgs channel URLs : http://repo.continuum.io/pkgs/gpl/win-32/ http://repo.continuum.io/pkgs/gpl/noarch/ http://repo.continuum.io/pkgs/free/win-32/ http://repo.continuum.io/pkgs/free/noarch/ config file : $HOME\\.condarc is foreign system : False conda environments: - envs listed here- root * C:\\Anaconda sys.version: 2.7.6 |Anaconda 1.9.1 (32-bit)| (default... sys.prefix: C:\\Anaconda sys.executable: C:\\Anaconda\\python.exe conda location: C:\\Anaconda\\lib\\site-packages\\conda conda-build: C:\\Anaconda\\Scripts\\conda-build.bat conda-convert: C:\\Anaconda\\Scripts\\conda-convert.bat conda-env: C:\\Anaconda\\Scripts\\conda-env.exe conda-index: C:\\Anaconda\\Scripts\\conda-index.bat conda-skeleton: C:\\Anaconda\\Scripts\\conda-skeleton.bat Set up a virtual environment To avoid potential Python library/package dependency conflicts, it is a good practice to install new projects into their own development environment. Such environment includes a fresh copy of the Python binary together with a copy of the entire Python standard library. Let's create a virtual environment called pelican1 . conda create -n pelican1 python=2 The expected response is shown in Figure 1 and Figure 2 . Fig. 1. Creating virtual environment pelican1 . Fig. 2. Packages installed in the virt env pelican1 . Activate the new environment as: > activate pelican1 if everything went as expected, you should see the following text at the command prompt: [pelican1] c:\\Anaconda Pelican Finally, we proceed with the installation of Pelican package. In your terminal, execute: [pelican1] c:\\Anaconda >pip install pelican The progress will look similar to the following output. Downloading pelican-3.6.2-py2.py3-none-any.whl (129kB) Downloading Pygments-2.0.2-py2-none-any.whl (672kB) Downloading feedgenerator-1.7.tar.gz Downloading Unidecode-0.04.18.tar.gz (206kB) Downloading pytz-2015.4-py2.py3-none-any.whl (475kB) Downloading python_dateutil-2.4.2-py2.py3-none-any.whl (188kB) Downloading six-1.9.0-py2.py3-none-any.whl Downloading Jinja2-2.8-py2.py3-none-any.whl (263kB) Downloading docutils-0.12.tar.gz (1.6MB) Downloading blinker-1.4.tar.gz (111kB) Downloading MarkupSafe-0.23.tar.gz Installing collected packages: pygments, pytz, six, feedgenerator, unidecode, py thon-dateutil, markupsafe, jinja2, docutils, blinker, pelican Other Python packages Following are packages that I found useful when developing and publishing Pelican blog site. To make their installation easier, we will use the Requirements.txt file. Open a text editor and type (copy/paste) the following content. beautifulsoup4~=4.3.2 feedgenerator~=1.7 html5lib~=0.999 Markdown~=2.5.2 Pygments~=2.0.2 pyreadline~=2.0 smartypants~=1.8.6 typogrify~=2.0.7 gitpython Save the file as Requirements.txt into the folder C:\\Anaconda\\env\\pelican1\\ . Next, from the shell, issue the following command: [pelican1] c:\\Anaconda>pip install -r c:\\Anaconda\\envs\\pelican1\\requirements.txt To build, publish, and maintain the site, I use the Fabric Python library. To avoid complications with C++ compiler on Windows, use the Binstar package: [pelican1] c:\\Anaconda>conda install -c https://conda.binstar.org/binstar fabric The following packages will be installed. Note that pycrypto package may require compilation of C++ source, on Windows use MinGW or search for pycrypto binaries for your Python version. ecdsa: 0.11-py27_0 fabric: 1.10.1-py27_0 paramiko: 1.15.2-py27_0 pycrypto: 2.6.1-py27_3 At this point, the size of pelican1 environment is about 100Mb. Pelican blog So far, all packages were installed in the C:\\Anaconda\\env\\pelican1\\ folder. The actual blog files require different drive/folder location from which the site is managed. Let's create such directory, for example, C:\\demo\\pelicanblog . Now, while still in the pelican1 virtual environment, cd into this directory: [pelican1] c:\\Anaconda\\envs\\pelican1 >cd c:\\demo\\pelicanblog To initiate this new blog/web site, run the quickstart script and answer the setup questions. Note that I have chosen not to use GitHub Pages and secure SSH protocol for upload. The latter will be addressed below. [pelican1] C:\\demo\\pelicanblog> pelican-quickstart > Where do you want to create your new web site? [.] (just press enter; it will be in the /pelicalblog directory; in this case c:\\demo\\pelicanblog) > What will be the title of this web site? Blogging with Pelican > Who will be the author of this web site? your name > What will be the default language of this web site? [en] > Do you want to specify a URL prefix? e.g., http://example.com (Y/n) y > What is your URL prefix? (see above example; no trailing slash) http://www.yourdomain.com/blog > Do you want to enable article pagination? (Y/n) y > How many articles per page do you want? [10] 8 > What is your time zone? [Europe/Paris] America/Phoenix > Do you want to generate a Fabfile/Makefile to automate generation and publishing? (Y/n) y (create fabfile.py) > Do you want an auto-reload & simpleHTTP script to assist with theme and site development? (Y/n) y > Do you want to upload your website using FTP? (y/N) y > What is the hostname of your FTP server? [localhost] ftp.yourdomain.com > What is your username on that server? [anonymous] username > Where do you want to put your web site on that server? [/] /blog > Do you want to upload your website using SSH? (y/N) n > Do you want to upload your website using Dropbox? (y/N) n > Do you want to upload your website using S3? (y/N) n > Do you want to upload your website using Rackspace Cloud Files? (y/N) n > Do you want to upload your website using GitHub Pages? (y/N) n A little more explanation on the \"URL prefix\" question. Answer yes and enter URL in the next step only if you have external web hosting site. Let's take a look at the just created folder structure within the c:\\demo\\pelicanblog directory. Now if you type the tree command within your blog's main directory, you should see a directory tree similar to this one: pelicanblog/ ├── content │ └── firstblog.md ├── output │ ├── author/ │ ├── category/ │ ├── tag/ │ ├── theme/ │ ├── archives.html │ ├── authors.html │ ├── Blogging with Pelican.html │ ├── categories.html │ ├── index.html │ └── tags.html ├── fabfile.py ├── pelicanconf.py └── publishconf.py Breaking down each of these files: content/firstblog.md : A content file in Markdown syntax. This is where you start writing your blog. output/ : Content of this folder is automatically generated and later uploaded to a server. fabfile.py : Is a configuration file for Fabric , which allows you to generate your site using the fab command . pelicanconf.py : Is a Pelican configuration file containing the site settings . publishconf.py : Similar to pelicanconfig.py file, but is not intended to be used for local development. Building the site Now let's build the default look of the blog. In your terminal, type the fab command after the > character: [pelican1] C:\\demo\\pelicanblog>fab build Then [pelican1] C:\\demo\\pelicanblog>fab serve We've just launched a local webserver on the port 8000. Open your browser and navigate to http://localhost:8000 the default skeleton and template should display in your browser. Fig. 3. Final view of the site. To avoid repetitive typing in the terminal, set up a batch file, which will get you directly to the [pelican1] C:\\demo\\pelican environment and directory. Save the following script as pelican.bat and place the file into C:\\Windows\\System32 directory. @echo off REM add this batch file into C:/windows/system32 REM run upon opening cmd as >pelican.bat set SERVE=C:\\demo\\pelicanblog cd /D %SERVE% activate pelican1 Next time, upon launching the command line terminal ( cmd.exe ), just type pelican.bat and the script will execute. To change or tweak the site settings, edit files pelicanconf.py and fabfile.py created in the main pelicanblog/ directory. # pelicanconf.py from __future__ import unicode_literals AUTHOR = u 'yourname' # Change it here SITENAME = u 'Blogging with Pelican' # Change it here SITEURL = '' PATH = 'output' # This is where you write blogs, keep images, css, .. TIMEZONE = 'America/Phoenix' # Change it here DEFAULT_LANG = u 'en' # other functions (default) # fabfile.py # default variables and functions follow # ... # Added site upload function to circumvent setup of rsync on Windows env . hosts = [ 'ftp.yourdomain.com' ] env . user = \"username\" env . password = \"serverpassword\" # or just entered it when connecting from fabric.context_managers import cd def sftp (): # run from the parent directory /pelicanblog/ with lcd ( 'output' ): # cd into output directory local ( \"dir\" ) # list files and directories to be uploaded put ( '*' , './public_html/yourblogdirectory/' ) # change here Note the sftp() function added at the end of the fabfile.py . The default publish() function is based on rsync utility that is not that easy to install on Windows. Instead, we can use the SSH File Transfer Protocol (sftp) protocol, which is also secure an simple to implement. In order to use sftp protocol to safely upload your site to a web-hosting server, you will need to enable SSH/Shell access on your hosted account. Major web-hosting sites support both ftp and sftp protocols. Now, let's move on and start working on the first blog. Markdown .md file To create the content of our new web site, we will use the Markdown syntax 5 , 6 . Let's create our first markdown file name it firstblog.md . Save it into the /pelicanblog/content folder. Title: First Blog Post Date: 2015-8-08 13:10 Category: Blogging Tags: blogging, markup Slug: Blogging with Pelican Author: yourname Summary: Collection of notes related to programming and scripting. Latex: # Work in progress # Following are examples of Pelican markup. This is a **first** attempt to create static page with the help of _Pelican_. Rendering and uploading the site At this point, we will move back to the terminal and issue the following commands. [pelican1] C:\\demo\\pelicanblog>fab build [pelican1] C:\\demo\\pelicanblog>fab serve Now, in the browser type http://localhost:8000 and our modified (local) site should load. To upload it to a web-server, make sure that you create your blog directory at the remote site first. Note the path to it, e.g. /public_html/yourblogdirectory. Enter your host name and user name into the fabfile.py file. In your terminal, enter: [pelican1] C:\\demo\\pelicanblog>fab sftp Upload process should start immediately with a list of files to be uploaded and a prompt for your password. After the upload is done, head to the site and check its accessibility. And we are done This concludes the process of setting up a simple Pelican site on Windows and Python Anaconda environment. We have built the skeleton of Pelican static web-site in Python virtual environment, modified its configuration files, and uploaded the site to our hosting server. Pelicanblog files can be downloaded from here . This blog is built with Pelican as well and it is styled with customized Pelican-bootstrap3 theme. References Making a Static Blog with Pelican . ↩ Using pelican to generate static sites on windows ↩ Creating a Blog on GitHub.io with Python ↩ Creating your blog with Pelican ↩ ↩ Markdown Cheatsheet ↩ ↩ from Darin Fireball ↩","tags":"Blogging","title":"Blogging with Python, Anaconda, and Pelican on Windows"}]}