var tipuesearch = {"pages":[{"title":"About","text":"I am a chemist by training, passionate about organic chemistry, the discovery of new medicines, and computer technologies. I have enjoyed chemistry since my teenage and keep enjoying it today. Throughout my career, it was the scientific curiosity that led me into scientific disciplines of organic chemistry , combinatorial chemistry , medicinal chemistry , peptide synthesis , drug design , cheminformatics , and computational chemistry . Over the years, I have been intrigued by molecular structures and physico-chemical properties of molecules. After mastering the basics of computational chemistry, I kept coming back to practical approaches to molecular models and molecular visualization. At one time, when immersed in a peculiar chemical puzzle, I run across the concept of Natural Bond Orbitals (NBO) . I found it extremely useful, and I am learning and using it since. I enjoy writing simple applications and scripts to make processing and understanding the results of NBO explorations easier. On the business side, I enjoy my engagement in the consulting work at Bright Rock Path , LLC . My projects cover various aspects of early-stage drug discovery from hit identification to lead optimization to clinical candidates. I found that those services best fit Small Biotechs seeking pharma-grade expertise , Academic Groups that are developing and expanding their programs and grants in drug discovery. I also work with various Research and Investment Consultancies to advise on research strategies and tactical planning at major corporations, investment funds, and non-profits. As for my hobbies, I enjoy digital photography , color science, web design, and coding. An arsenal of my scripting and programming tools includes HTML, CSS, jQuery, PHP, Java, and Python.","tags":"misc","url":"https://marpat.github.io/pages/about.html","loc":"https://marpat.github.io/pages/about.html"},{"title":"Contacts","text":"The best way to contact me is by e-mail. # My contact e-mail is: email = ( \"chem g plus a t g ma il dot com\" ) . replace ( \" \" , \"\" ) Just kidding, click the button below. I'm on LinkedIn and you can also find me on Twitter @mpatek_ . Show/Hide email","tags":"misc","url":"https://marpat.github.io/pages/contact.html","loc":"https://marpat.github.io/pages/contact.html"},{"title":"Blogging with Python, Miniconda, and Pelican on Windows","text":"Introduction With so many blogs and descriptive how-to's out there 1 , 2 , 3 , 4 , 5 , 6 , one may be wondering why another post on Pelican static site generator. The purpose of this blog is to provide an entry level document for building a static web site in Windows environment with Miniconda Python distribution. This tutorial assumes very little, so we will cover each step in a little more details. Chances are that you have already heard about the the Python-powered micro web frameworks, static page generators, and even about Pelican , Nikola , or Flask . If not, this blog 7 has a nice introduction. Pelican is a static web page generator that delivers web pages to the user exactly as they are stored on the server. There is no user-interaction possible once the pages are rendered. In contrast, dynamic web pages are generated and updated by a web application. Pelican is written in Python (2 or 3) and it is platform independent. Requirements Before we get started, we'll need a base installation of Python , and of course, the Pelican . The following are the minimum requirements: Python 3.5 or higher (aka Python 3), but Python 2.7 (aka Python 2) works also Pelican package (v4 +) Text editor (e.g., Notepad++ , Markdown Pad2 , Sublime Text , or Typora ) Web server for the web hosting Python First, we need a Python installation. I recommend Anaconda or Miniconda , both being a distribution of Python from the company Anaconda . Anaconda and Miniconda are free and the former comes with many pre-installed Python packages and libraries such as Pandas, NumPy, matplotlib, and others. The latter, is a minimal installer for conda. It is a small, bootstrap version of Anaconda that includes only conda, Python, the packages they depend on, and a small number of other useful packages, including pip, zlib and a few others. However, neither installation includes Pelican site generator. If you already have Python installed, skip to the section Virtual Environment . To get Anaconda/Miniconda installed under the Windows, download the latest binary package [ Anaconda | Miniconda ] and install the executable. This tutorial is using Miniconda although steps with Anaconda are the same. The typical (and default) path to install Miniconda on Windows is: C:\\Miniconda3 . When installation completes, append the following string into your system PATH or make sure that it is written there by the installer: C:\\Miniconda3;C:\\Miniconda3\\Lib;C:\\Miniconda3\\DLLs;C:\\Miniconda3\\Lib\\lib-tk;C:\\Miniconda3\\Scripts; To access the PATH variable, right-click on Computer ⇒ Advanced system settings ⇒ Advance tab ⇒ Environment Variables ⇒ System variables ⇒ Path. Note that the latest Anaconda/Miniconda installation binaries set the correct path if checked during the install. To check that Miniconda has installed successfully, launch the Windows command shell (cmd.exe) and execute the command: conda info -- all A typical (shortened) output follows: Current miniconda install: platform : win-64 python version : 3.6.7.final.0 user config file : $HOME.condarc Set up a virtual environment To avoid potential Python library/package dependency conflicts, it is a good practice to install new projects into their own development environment. Such environment includes a fresh copy of the Python binary together with a copy of the entire Python standard library. Most importantly, if any file gets corrupted, one can simple remove and re-install the environment. Let's create a virtual environment called pelican1 . conda create - n pelican1 python = 3.6 The expected response is shown in Figure 1 and Figure 2 . Fig. 1. Creating virtual environment pelican1 . Fig. 2. Packages installed in the virt env pelican1 . Anywhere on your computer, make a new folder for your blog items (e.g., blog) and activate the new environment as: > cd path\\to\\blog > conda activate pelican1 if everything went as expected, you should see the following text at the command prompt: (pelican1) drive:\\\\path\\to\\blog Pelican Finally, we proceed with the installation of the Pelican package. In your terminal, execute: (pelican1) drive:\\\\path\\to\\blog >conda install pelican The progress will look similar to the following output. Downloading pelican - 3.6 . 2 - py2 . py3 - none - any . whl ( 129 kB ) Downloading Pygments - 2.0 . 2 - py2 - none - any . whl ( 672 kB ) Downloading feedgenerator - 1.7 . tar . gz Downloading Unidecode - 0.04 . 18. tar . gz ( 206 kB ) Downloading pytz - 2015.4 - py2 . py3 - none - any . whl ( 475 kB ) Downloading python_dateutil - 2.4 . 2 - py2 . py3 - none - any . whl ( 188 kB ) Downloading six - 1.9 . 0 - py2 . py3 - none - any . whl Downloading Jinja2 - 2.8 - py2 . py3 - none - any . whl ( 263 kB ) Downloading docutils - 0.12 . tar . gz ( 1.6 MB ) Downloading blinker - 1.4 . tar . gz ( 111 kB ) Downloading MarkupSafe - 0.23 . tar . gz Installing collected packages : pygments , pytz , six , feedgenerator , unidecode , py thon - dateutil , markupsafe , jinja2 , docutils , blinker , pelican Other Python package Following are packages that I found useful when developing and publishing Pelican blog site using Jupyter notebooks. To make their installation easier, we will use the packages.yml file. Open a text editor and type (copy/paste) the following content. name: pelican1 channels: - conda-forge - defaults dependencies: - bs4 - html5lib - Markdown - fabric3 - typogrify - invoke - MarkupSafe - livereload - pybtex - jupyter prefix: C:\\Miniconda3\\envs\\pelican1 Save the file as packages.yml into the folder C:\\Miniconda3\\envs . Next, from the shell, issue the following command: (pelican1) c:\\Miniconda3\\envs > conda env update --file packages.yml In case that you plan on using Disqus platform for comments and discussion on your articles, install the following package directly from the GitHub: pip install git + https : // github . com / disqus / disqus - python . git and add \"disqus_static\" entry into the PLUGINS list in pelicanconf.py. To build, publish, and maintain the site, I use the Fabric Python library. At this point, the size of pelican1 environment is about 100Mb. Pelican blog So far, all packages were installed in the C:\\Miniconda3\\env\\pelican1\\ folder. The actual blog files require different drive/folder location from which the site is managed. Let's create such directory, for example, F:\\Blog\\pelican . Now, while still in the pelican1 virtual environment, cd into this directory: (pelican1) c:\\Miniconda3\\envs\\pelican1 >cd F:\\Blog\\pelican To initiate this new blog/web site, run the quickstart script and answer the setup questions. Note that I have chosen not to use GitHub Pages and secure SSH protocol for upload. The latter will be addressed below. (pelican1) F:\\Blog\\pelican> pelican-quickstart > Where do you want to create your new web site? [.] (just press enter; it will be in the /pelicalblog directory; in this case F:\\Blog\\pelican) > What will be the title of this web site? Blogging with Pelican > Who will be the author of this web site? your name > What will be the default language of this web site? [en] > Do you want to specify a URL prefix? e.g., http://example.com (Y/n) y > What is your URL prefix? (see above example; no trailing slash) http://www.yourdomain.com/blog > Do you want to enable article pagination? (Y/n) y > How many articles per page do you want? [10] 8 > What is your time zone? [Europe/Paris] America/Phoenix > Do you want to generate a Fabfile/Makefile to automate generation and publishing? (Y/n) y (create fabfile.py) > Do you want an auto-reload & simpleHTTP script to assist with theme and site development? (Y/n) y > Do you want to upload your website using FTP? (y/N) y > What is the hostname of your FTP server? [localhost] ftp.yourdomain.com > What is your username on that server? [anonymous] username > Where do you want to put your web site on that server? [/] /blog > Do you want to upload your website using SSH? (y/N) n > Do you want to upload your website using Dropbox? (y/N) n > Do you want to upload your website using S3? (y/N) n > Do you want to upload your website using Rackspace Cloud Files? (y/N) n > Do you want to upload your website using GitHub Pages? (y/N) n A little more explanation on the \"URL prefix\" question. Answer yes and enter URL in the next step only if you have external web hosting site. Let's take a look at the just created folder structure within the F:\\Blog\\pelican directory. Now if you type the tree command within your blog's main directory, you should see a directory tree similar to this one: pelican/ ├── content │ └── firstblog.md ├── output │ ├── author/ │ ├── category/ │ ├── tag/ │ ├── theme/ │ ├── archives.html │ ├── authors.html │ ├── Blogging with Pelican.html │ ├── categories.html │ ├── index.html │ └── tags.html ├── fabfile.py ├── pelicanconf.py └── publishconf.py Breaking down each of these files: content/firstblog.md : A content file in Markdown syntax. This is where you start writing your blog. output/ : Content of this folder is automatically generated and later uploaded to a server. fabfile.py : Is a configuration file for Fabric , which allows you to generate your site using the fab command . pelicanconf.py : Is a Pelican configuration file containing the site settings . publishconf.py : Similar to pelicanconfig.py file, but is not intended to be used for local development. Building the site Now let's build the default look of the blog. In your terminal, type the fab command after the > character: (pelican1) F:\\Blog\\pelican>fab build Then (pelican1) F:\\Blog\\pelican>fab serve We've just launched a local webserver on the port 8000. Open your browser and navigate to http://localhost:8000 the default skeleton and template should display in your browser. Fig. 3. Final view of the site. To avoid repetitive typing in the terminal, set up a batch file, which will get you directly to the (pelican1) F:\\Blog\\pelican environment and directory. Save the following script as pelican.bat and place the file into C:\\Windows\\System32 directory. @echo off REM add this batch file into C:/windows/system32 REM run upon opening cmd as >pelican.bat REM 'path\\to\\blog' example F:\\Blog\\pelican set SERVE=path\\to\\blog cd /D %SERVE% conda activate pelican1 Next time, upon launching the command line terminal ( cmd.exe ), just type pelican.bat and the script will execute. To change or tweak the site settings, edit files pelicanconf.py and fabfile.py created in the main path\\to\\blog directory. # pelicanconf.py from __future__ import unicode_literals AUTHOR = u 'yourname' # Change it here SITENAME = u 'Blogging with Pelican' # Change it here SITEURL = '' PATH = 'output' # This is where you write blogs, keep images, css, .. TIMEZONE = 'America/Phoenix' # Change it here DEFAULT_LANG = u 'en' # other functions (default) # fabfile.py # default variables and functions follow # ... # Added site upload function to circumvent setup of rsync on Windows env . hosts = [ 'ftp.yourdomain.com' ] env . user = \"username\" env . password = \"serverpassword\" # or just entered it when connecting from fabric.context_managers import cd def sftp (): # run from the parent directory /pelicanblog/ with lcd ( 'output' ): # cd into output directory local ( \"dir\" ) # list files and directories to be uploaded put ( '*' , './public_html/yourblogdirectory/' ) # change here Note the sftp() function added at the end of the fabfile.py . The default publish() function is based on rsync utility that is not that easy to install on Windows. Instead, we can use the SSH File Transfer Protocol (sftp) protocol, which is also secure an simple to implement. In order to use sftp protocol to safely upload your site to a web-hosting server, you will need to enable SSH/Shell access on your hosted account. Major web-hosting sites support both ftp and sftp protocols. Now, let's move on and start working on the first blog. Markdown .md file To create the content of our new web site, we will use the Markdown syntax 8 , 9 . Let's create our first markdown file name it firstblog.md . Save it into the /pelican/content folder. Title: First Blog Post Date: 2020-4-5 13:10 Category: Blogging Tags: blogging, markup Slug: blogging-with-pelican Author: yourname Summary: Collection of notes related to programming and scripting. Latex: # Work in progress Following are examples of Pelican markup. This is a **first** attempt to create static page with the help of _Pelican_ . Rendering and uploading the site At this point, we will move back to the terminal and issue the following commands. (pelican1) F:\\Blog\\pelican>fab build (pelican1) F:\\Blog\\pelican>fab serve Now, in the browser type http://localhost:8000 and our modified (local) site should load. To upload it to a web-server, make sure that you create your blog directory at the remote site first. Note the path to it, e.g. /public_html/yourblogdirectory. Enter your host name (e.g., https://my.site.com) and user name into the fabfile.py file as shown above. In your terminal, enter: (pelican1) F:\\Blog\\pelican>fab sftp Upload process should start immediately with a list of files to be uploaded and a prompt for your password. After the upload is done, head to the site and check its accessibility (e.g., https://my.site.com/yourblogdirectory/index.html). What's been accomplished This concludes the process of setting up a simple Pelican site on Windows and Python miniconda environment. We have built the skeleton of Pelican static web-site in Python virtual environment, modified its configuration files, and uploaded the site to our hosting server. References: How I built this site ↩ Blog migrated to Pelican and GitHub pages ↩ Making a Static Blog with Pelican ↩ Using pelican to generate static sites on windows ↩ Creating your blog with Pelican ↩ How to Create Your First Static Site with Pelican and Jinja2 ↩ Creating a Blog on GitHub.io with Python ↩ Markdown Cheatsheet ↩ from Darin Fireball ↩","tags":"Blogging","url":"https://marpat.github.io/python-miniconda-and-pelican-on-windows.html","loc":"https://marpat.github.io/python-miniconda-and-pelican-on-windows.html"},{"title":"Create html Report from Jupyter Notebook on Windows","text":"Introduction While Jupyter notebook has a built-in facility for multiple output formats, its use depends on OS platform and requirements on the output file. Perhaps the most requested output is pdf format currently done in two-steps: html to latex to pdf. 1 Unfortunately for those working on Windows, Latex rendering requires installation of MiKTexT , Tex Live preferred by Jupyter and Latex editor, such as TeXstudio . The process of getting output similar to the original notebook is quite convoluted and impractical. An alternative solution is to print notebook directly to pdf format, assuming that one has installed the pdf writer (driver) on Windows. Print-to-pdf is the done by choosing the pdf from the list of available printers in the print dialog. There are two issues that one may face should the desired report preserve color and be within the code cells . Let's start with an illustration of sample Jupyter notebook as rendered by Jupyter. Fig. 1. Rendering of the original Jupyter notebook. Alternatively, the complete Jupyter notebook is at this link: Sample_ipynb.ipynb First, we export the notebook as html file: Fig. 2. Exporting notebook as .html file. Color rendering Printing the notebook directly (File -> Print Preview -> print (Ctrl+P)) to a printer device renders the notebook in black and white 2 . Fig. 3. B&W rendering of html file at the print. The culprit here is one line in the embedded style under the @media print section, specifically, color: #000 !important . This instruction overwrites default and custom colors, setting black-white as default print output. Fig. 4. css/style instructions to overwrite colors. This offending line is coming from the Bootstrap 3 .less template, which is part of the Jupyter notebook styling. There are three solutions: one is to edit out this line in the .less file and recompile the new default css file for notebooks. the second solution is to comment out the color: #000 !important line in the style.min.css file 3 , and the third approach is to remove the same line from the embedded style section in exported (rendered) html file. Last two approaches are demonstrated here. Editing Bootstrap style.min.css file: Locate the Jupyter default style sheet style.min.css in: minconda3\\Lib\\site-packages\\notebook\\static\\style\\style.min.css or minconda3\\envs\\[your_environment]\\Lib\\site-packages\\notebook\\static\\style\\style.min.css and search for the phrase #000 !im . Comment out the line shown below and save: @ media print { *, * : before , * : after { background : transparent !important ; /*color: #000 !important;*/ /*<---- comment out this line*/ box-shadow : none !important ; text-shadow : none !important ; } Editing the rendered .html file file After creating html file in Jupyter notebook like so: File -> Download as -> HTML (html) comment out the same line as above and save. Code Cells Since notebooks are often used for education and collaborative projects, output of the code cells has been often a desired feature. On the other hand, should the ultimate result be a report for the customer, code cells could be quite distracting. Fig. 5. Report with visible code cell. One way to suppress visibility of code cell is to use JQuery (javascript) in the separate Jupyter cell as per 4 , 5 : # Run (once) to allow nice html output as report (optional) \"\"\" Hide code cells in an IPython notebook or exported HTML using javascript. \"\"\" import IPython.core.display as di # This line will hide code by default when the notebook is exported as HTML di . display_html ( '<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area, .output_stderr\").toggle(); jQuery(\".prompt\").toggle();}});</script>' , raw = True ) CSS = \"\"\".input_area .output_stderr {height: 2.0em; overflow: hidden}\"\"\" # changes input_subarea width to 1 visible line HTML ( '<style> {} </style>' . format ( CSS )) # This line will add a button to toggle visibility of code blocks, for use with the HTML export version. di . display_html ( '''<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Click in rendered .html output only, toggles the code</button>''' , raw = True ) We can toggle visibility of the code in the html report (rendered output) displayed in the browser. To remove the code completely, one can add a Jinja2 template into nbconvert-templates directory. For example, create file report.tpl with the following content and place it into the html directory under template folder 6 . {%- extends 'full.tpl' -%} {%-block input_group scoped-%} {%- if 'jupyter:' and cell.cell_type == 'code'-%} {%- endif -%} {%-endblock input_group -%} The full default path to your Jupyter templates is: # In my case C : / miniconda3 / envs / [ my_environment ] / Lib / site - packages / nbconvert / templates / html # or in general your_Python_path / Lib / site - packages / nbconvert / templates / html Then add the following cell at the end of your Jupyter notebook: # Create output with a template. Input code is removed from nbconvert import HTMLExporter import codecs import os # Prepare a date/time stamp to prepend to the report filename stamp = datetime . today () . strftime ( \"%m_ %d _%Y\" ) exporter = HTMLExporter ( template_file = 'report.tpl' ) output , resources = exporter . from_filename ( 'Sample_ipynb.ipynb' ) new_fnm = stamp + '_sample_report.html' codecs . open ( new_fnm , 'w' , encoding = 'utf-8' ) . write ( output ) In this particular case, file called sample_report.html with prepended date-stamp will be created in your notebook directory. Now, for the completeness, we can add one more cell with code to remove the color: #000 !important line from the html file: # Delete 'print B&W' instruction in css/style section program = open ( new_fnm , \"r\" ) lines = program . readlines () program . close () f = open ( stamp + '_sample_report_print.html' , \"w\" ) for line in lines : if not line . startswith ( ' color: #000 !important' ): f . write ( line ) f . close () os . remove ( new_fnm ) Here is the rendered version of the notebook just before printing with link to complete html file: sample_report_print Fig. 6. Final report at the print stage. Other ways to create reports To further customize the appearance of the report, html file without the code cells and stripped of the color: #000 !important line, the file is first rendered in the browser, its content selected (ctrl+a, ctrl+c) and pasted into new MS Word (Google Docs) document. The style of paragraphs and tables can be changed in the word editor. At this point, we should be very close to the final report style with a much improved visual appeal. References: Jessica Yung, Converting Jupyter Notebooks to PDFs ↩ GitHub, Color printing should be an option ↩ Ilho Song, Mid the Gap ↩ Max Masnick, how-to-hide-code-from-cells-in-ipython-notebook-visualized-with-nbviewer ↩ Jörg Dietrich, Blogging with IPython and Collapsible Input Cells ↩ Gregory Ashton, Ipython NBConvert latex template to hide code ↩","tags":"Jupyter","url":"https://marpat.github.io/jupyter-notebook-html-report.html","loc":"https://marpat.github.io/jupyter-notebook-html-report.html"},{"title":"Natural Dipole Analysis","text":"Blogging with IPython Notebook IPython Notebook ( Jupyter notebook ) is a web-based interactive computing platform that combines live code, equations, text, images, and other media. These documents provide a complete record of computation approach that can be shared with others. Also, the IPython Notebook is not only a tool for scientific research and data analysis, but also a great tool for teaching. Technically, Notebook launches a web-based shell to an IPython session that has handy features, like the ability to save, edit, and delete lines of code. The code is organized into cells of Python, text, or Markdown. One can move the cells around, develop code interactively with documentation and notes, display objects that a browser can render (e.g., images, HTML, videos) and to share the whole notebook for a collaborative work. To demonstrate the utility and benefits of using IPython Notebook, the notebook decribed in this blog discusses Python code to analyse Natural dipole moment and its components. Steps of installing iPython notebook on Windows (as a part of Anaconda package) are described in blog \"Analyzing NBO Results with IPython Notebook\" This notebook discusses Python code to analyse Natural dipole moment of planar molecules. In the \" DIPOLE MOMENT ANALYSIS \" section, the NBO output file (.nbo, .out) contains individual x,y,z-components and length of the total molecular dipole moment. Each of the entries is decomposed into individual NLMO and NBO bond contributions. On the example of formamide, we are going to extract those lines and build a vector (NLMO) representation of the total molecular dipole. Similar method using Java-based KNIME platform is described here . Details of the formamide analysis can be found in the excellent book of Weinhold and Landis: Weinhold, F. and Landis, C.R. in Discovering Chemistry with Natural Bond Orbitals , pp. 147-152. Planar geometry of formamide Electric Dipole Electric dipole moment is the most fundamental quantity related to the charge distribution in a molecule. It reflects the degree to which positive and negative charge is distributed relative to one another. Dipole moment is a vector quantity characterized by its scalar magnitude, sign, and direction. Accordingly, the dipole can be described by its vector μ directed from the negative to the positive charge. Magnitude of the dipole moment is defined as: $$\\mu = |q|*R,$$ where q is charge and R is the displacement vector pointing from the negative to positive charge. The net dipole moment of a molecule can be conceptually described as a vector sum of the individual moments. This is what we will attempt to do in the following cells. Styling and Imports First the custom styling. File *.css inserts contents of custom .css file into the header of the notebook's HTML file. Other variants of .css files are in the ./css directory and differ only in color decoration of iPython notebook cells. This step is optional and the if ... else statement can be commented out. In [1]: %%capture # suppress output; remove %% capture for debugging # to (de)activate line numbering pres Esc while in the cell # followed by l (lower L) '''Sanity check since we are changing directories and *.css file path would be incorrect after cell re-run''' from IPython.core.display import HTML import string , sys , os , os.path , re css_file = './css/blog.css' if os . path . isfile ( css_file ): css_file else : % cd .. HTML ( open ( css_file , \"r\" ) . read ()) csv to Dataframe In the next step, coordinates of NLMO dipoles are read from *.csv file. This file was generated earlier using the KNIME \"Dipole_v2/3\" workflow . Alternatively, iPython notebook ReadNboDip.ipynb at this Github repository creates the identical input file. \"Plain\" Python script ( ReadNboDip.py ) that parses NBO output files for the same Dipole moment summary can be downloaded from this Github repository . In this example, this file is available from the ./dipole directory. In [3]: %%capture # Step into the directory of input .csv files using the magic %cd # Make sure that we are not already in the 'dipoles' dir from the previous run if os . path . isdir ( 'dipoles' ): % cd dipoles else : % cd .. % cd dipoles First, a row of arbitrary values (zeroes) is inserted at the top of dataframe df (line 15; press Esc+l (lower L)) and the table values are assigned int, float, or string types, respectively. In [ ]: # Input file can be generated in ReadNboDip.ipynb notebook infile = 'form_dip.csv' # in directory ./dipoles # Save the file path, name and extension fullpath = os . path . abspath ( infile ) path , file = os . path . split ( fullpath ) basename , extension = os . path . splitext ( infile ) # Create Pandas dataframe from the *.csv file df = pd . read_csv ( infile ) # fix datatype for columns df . convert_objects ( convert_numeric = True ) . dtypes # Prepare first blank row with XYZ=0 to set the point of vector origin # set the first row to zeroes rowex = df . loc [[ 0 ]] # Get dataframe column headers headers = df . columns . values . tolist () # Fix the data types for item in headers : if df . dtypes [ item ] == 'float64' : rowex [ item ] = 0. elif df . dtypes [ item ] == 'int64' : rowex [ item ] = 0 else : rowex [ item ] = '' row0 = rowex In [5]: # Reassemble data table placing row0 at the top, followed by the rest df2 = pd . concat ([ row0 , df ]) . reset_index () . ix [::] # print df2 In [6]: \"\"\" Identify which column (coordinate) has constant values (orthogonal to the molecular plane). \"\"\" # Prepare stds of absolute values for each x,y,z column # Smallest stds indicate constant dimension perpendicular to 2D plane C1 = df2 [ \"X\" ] . abs () C1std = C1 . std () C2 = df2 [ \"Y\" ] . abs () C2std = C2 . std () C3 = df2 [ \"Z\" ] . abs () C3std = C3 . std () # print \"stds are: %.3f %.3f %.3f\" % (C1std, C2std, C3std) In [7]: '''Assign X,Y coordinates only, Z=0. Any of the X,Y,Z can be constant or zero 0 (which one may change every time). Remap coordinates arbitrarily to X,Y with Z=[const] ''' def coord_headers ( C1std , C2std , C3std ): if C1std > 0.1 and C2std > 0.1 > C3std : df2 [ 'newX' ] = df2 [ \"X\" ] df2 [ 'newY' ] = df2 [ \"Y\" ] elif C1std > 0.1 > C2std and C3std > 0.1 : df2 [ 'newX' ] = df2 [ \"X\" ] df2 [ 'newY' ] = df2 [ \"Z\" ] elif C1std < 0.1 < C2std and C3std > 0.1 : df2 [ 'newX' ] = df2 [ \"Y\" ] df2 [ 'newY' ] = df2 [ \"Z\" ] else : df2 [ 'newX' ] = df2 [ \"X\" ] df2 [ 'newY' ] = df2 [ \"Y\" ] In [8]: # Append columns newX,newY to df2 (values are often same as the original X,Y) # Plane defined coord_headers ( C1std , C2std , C3std ) # Remove rows with CR (core) orbitals and reindex the dataframe df2 = df2 [ ~ df2 [ 'Type' ] . str . contains ( \"CR\" )] # Copy dataframe for the intermediate output df2b1 = df2 . reset_index () . ix [::] # Comment off if re-running the cell HTML ( df2b1 . to_html ( classes = 'grid' , escape = False )) # table styling requires package qgrid http://nbviewer.ipython.org/github/quantopian/qgrid/ # blob/master/qgrid_demo.ipynb Out[8]: level_0 index NLMO Type X Y Z Tot_Dip newX newY 0 0 0 0 0.00 0 0.00 0.00 0.00 0.00 1 4 3 4 LP ( 1) N 1 -0.20 0 -1.64 1.65 -0.20 -1.64 2 5 4 5 LP ( 1) O 3 -2.37 0 -1.64 2.88 -2.37 -1.64 3 6 5 6 LP ( 2) O 3 0.89 0 0.75 1.16 0.89 0.75 4 7 6 7 BD ( 1) N 1- C 2 0.02 0 0.85 0.85 0.02 0.85 5 8 7 8 BD ( 1) N 1- H 4 -0.68 0 0.47 0.82 -0.68 0.47 6 9 8 9 BD ( 1) N 1- H 5 0.75 0 0.46 0.88 0.75 0.46 7 10 9 10 BD ( 1) C 2- O 3 -1.90 0 -1.44 2.38 -1.90 -1.44 8 11 10 11 BD ( 2) C 2- O 3 -0.67 0 -0.46 0.81 -0.67 -0.46 9 12 11 12 BD ( 1) C 2- H 6 1.72 0 -0.58 1.82 1.72 -0.58 Table 1 . Current df2 with new columns for consolidated X, Y coordinates. First Plot Now, to have dipole vectors continue from one to another (as opposed to all starting at the zero), we have to transpose coordinates in a way that the origin of new vector starts at the end of the previous vector. In Python, use the function cumsum() . Let's try to build continuous vector graph from the original dataframe df2 . This is equivalent to a vector decomposition. **The following cell is just a test case** (can be removed later). It generates plot of Table 1 as continuing vector segments. You can skip it and go to section \"Cleaning up the Vector Path\" . In [9]: # Test area running off the branch df2b1 # Translate coordinates from X,Y,Z=0,0,0 to assure vector continuity df2b1 [ 'newXa' ] = df2b1 . newX . cumsum () df2b1 [ 'newYa' ] = df2b1 . newY . cumsum () df3b = df2b1 # print df3b # Calculate total dipole (compare with column Tot_Dip) lastX = df3b . tail ( 1 ) . newXa # row and value lastX = lastX . tolist ()[ 0 ] # value only lastY = df3b . tail ( 1 ) . newYa lastY = lastY . tolist ()[ 0 ] total_dipole = sqrt ( np . power ( lastX , 2 ) + np . power ( lastY , 2 )) total_dipole = round ( total_dipole , 2 ) # Calc geometrical center of the vector polygon cenX = df3b [ 'newXa' ] . mean () cenY = df3b [ 'newYa' ] . mean () x = df3b . newXa y = df3b . newYa # Plot # Set rectangular plot dimensions to keep lengths proportional xlow = x . min () xhigh = x . max () ylow = y . min () yhigh = y . max () def lst_sort ( list ): ''' Sort list of floats by values. :type list: list of floats :param list: max and min x,y-coordinates :rtype: list of floats :return: sorted list of floats ''' abslist = [] for item in list : abslist . append ( item ) return sorted ( abslist ) margins = lst_sort ([ xlow , ylow , xhigh , yhigh ]) plt . figure () # To generate multiple distinct plots. plt . suptitle ( 'Dipole Moments (D)' ) ax = [] xmin = margins [ 0 ] - 1 #x.min()-1 xmax = margins [ 3 ] + 1 ymin = margins [ 0 ] - 1 ymax = margins [ 3 ] + 1 plt . ylabel ( 'Y' ) plt . xlabel ( 'X' ) plt . grid ( True ) plt . xlim ( xmin , xmax ) plt . ylim ( ymin , ymax ) color = 'blue' plt . scatter ( df3b . newXa , df3b . newYa , s = 80 , c = color , label = 'NLMOs' ) for j , txt in enumerate ( df3b [ 'NLMO' ]): plt . annotate ( txt , ( x [ j ] + 0.1 , y [ j ] + 0.3 )) ax = gca () ax . add_patch ( FancyArrowPatch (( 0 , 0 ),( lastX , lastY ), arrowstyle = '->' , mutation_scale = 20 , color = 'red' )) for k in range ( 1 , len ( x )): ax . add_patch ( FancyArrowPatch (( x [ k ], y [ k ]),( x [ k - 1 ], y [ k - 1 ]), arrowstyle = '<-' , mutation_scale = 20 , color = 'blue' )) plt . annotate ( total_dipole , xy = ( lastX / 2 * 0.9 , lastY / 2 * 1.1 ), color = 'red' , xycoords = 'data' , textcoords = 'offset points' ) plt . annotate ( \"+\" , xy = ( cenX , cenY ), color = 'red' , xycoords = 'data' , textcoords = 'offset points' ) C:\\Anaconda\\envs\\notebook\\lib\\site-packages\\matplotlib\\text.py:1857: UserWarning: You have used the `textcoords` kwarg, but not the `xytext` kwarg. This can lead to surprising results. warnings.warn(\"You have used the `textcoords` kwarg, but not \" Out[9]: <matplotlib.text.Annotation at 0x776b050> Cleaning up the Vector Path Resulting plot is rather cluttered and thus we will need to arrange dipoles in some way to get a more interpretable view. Since most molecules have center of the coordinate system placed somewhere at the center of the molecule, sorting dipole coordinates by xy-quadrant in which the dipole origin resides is a sensible approach. The following cartoon indicates how such quadrants are defined. We will write a function that assigns each row an arbitrary quadrant depending on the signs of coordinates x and y . To further arrange directions of lines in each quadrant, we will include another function that calculates slope of the line and we will sort by the quadrant (rank) and the slope . In [10]: # Function to rank XY-points into quadrants 0-3 def xyrank ( a , b , c , d , e , f ): ''' Assign qudrant value 1,2,3,4. :type inputs: floats and str :param inputs: X, Y, Q(1), Q(2), Q(3), Q(4) :rtype: str :return: quadrant number as str ''' if a > 0 and b > 0 : # [Q1] return c elif a > 0 > b : # [Q2] return d elif a < 0 and b < 0 : # [Q3] return e else : # [Q4] 1 a>0, b<0 return f # Function to calculate slope def slope ( a , b ): if a != 0 : slope = ( 1.0 * b / a ) # expects float return slope else : slope = 0 # for a = zero, set slope arbitrarily to 0 return slope Unfortunately, it is not obvious which sequence of quadrants will lead to the least cluttered dipole diagram. To make sure that we test all possibilities, we will evaluate all permutations of four quadrants, that is, 4! = 4 x 3 x 2 x 1 = 24 For each trial, we record an array of quadrants and standard deviation of distances of all vector origins from the graph origin (geometric center). Small stds should indicate even distribution of vectors around the origin (circle, ellipsoid, symmetrical polygon?). Standard deviation of distances together with the sequence of quadrants appear at the top of each plot. As we will see later, lowest stds are not necesarilly indicative of the \"clean\" graph shape. By no means the resulting vector plots indicate atom connectivity! It is the relative direction of dipole vectors that helps us to assess the importance and internal balance of NLMO orbitals within the molecule. In [11]: # Get the list of quadrant permutations # Four quadrants of a XY plot lst = [ 0 , 1 , 2 , 3 ] set ( list ( lst )) # Creates a set import itertools permlist = set ( itertools . permutations ( lst )) permlist = list ( permlist ) # Get permutation set into a list. Plot Survey For each set of qudrants, the code below will sort the dataframe by the quadrant and slope. The corresponding plot will be created and saved as .png image. Quadrant sequence is part of the filename. In [12]: %%capture # remove %%capture magic to see the plot and output # Iterate through the list of all quadrants global captarr captarr = [] captperm = [] for i in range ( len ( permlist )): # Apply function to the table values in each row; make a copy first df21 = df2 . copy () df21 [ \"xyRank\" ] = df2 . apply ( lambda row : xyrank ( row [ 'newX' ], row [ 'newY' ], permlist [ i ][ 0 ], permlist [ i ][ 1 ], permlist [ i ][ 2 ], permlist [ i ][ 3 ]), axis = 1 ) # Apply function to table values in a row df21 [ \"slope\" ] = df21 . apply ( lambda row : slope ( row [ 'newX' ], row [ 'newY' ]), axis = 1 ) toprow = df21 [: 1 ] # row with zero dipole # Directly change rank of the first row in the dataframe toprow . xyRank [ 0 ] = 4 # Isolate remaining data into rest (drop) rest1 = df21 . drop ( df21 . index [[ 0 , 0 ]]) # sort rest1 by xyRank, then by slope - descending df3 = rest1 . sort_index ( by = [ 'xyRank' , 'slope' ], ascending = [ False , False ]) # Put it back df3 = pd . concat ([ toprow , df3 ]) . reset_index () . ix [::] df3 = df3 . sort_index ( by = [ 'xyRank' , 'slope' ], ascending = [ False , False ]) # Translate coordinates from xyz=0,0,0 df3 [ 'newXa' ] = df3 . newX . cumsum () df3 [ 'newYa' ] = df3 . newY . cumsum () # Calculate total dipole lastX = df3 . tail ( 1 ) . newXa # row and value lastX = lastX . tolist ()[ 0 ] # value only lastY = df3 . tail ( 1 ) . newYa lastY = lastY . tolist ()[ 0 ] total_dipole = sqrt ( np . power ( lastX , 2 ) + np . power ( lastY , 2 )) total_dipole = round ( total_dipole , 2 ) # Calc distances of x,y and assess even distribution of points # around the geom center cenX = df3 [ 'newXa' ] . mean () cenY = df3 [ 'newYa' ] . mean () distX = abs ( cenX - df3 . newXa ) distY = abs ( cenY - df3 . newYa ) # distance from centroid distXY = np . sqrt ( distX * distX + distY * distY ) diststd = distXY . std () captarr . append ( round ( diststd , 1 )) captperm . append ( permlist [ i ]) print \"++++++++++ Rank list is : \" , permlist [ i ], \"; \\ std of distances is:\" , round ( diststd , 2 ) # Plot plt . figure () # To generate multiple distinct plots. plt . suptitle ( 'Dipole Moments (D)' ) ax = [] x = df3 . newXa y = df3 . newYa xmin = x . min () - 1 xmax = x . max () + 1 ymin = y . min () - 1 ymax = y . max () + 1 plt . ylabel ( 'Y' ) plt . xlabel ( 'X' ) plt . grid ( True ) plt . xlim ( xmin , xmax ) plt . ylim ( ymin , ymax ) color = 'blue' plt . scatter ( df3 . newXa , df3 . newYa , s = 80 , c = color , label = 'NLMOs' ) # plt.plot(df3.newXa, df3.newYa, c=color) # plt.legend(loc=1,borderaxespad=0.) for j , txt in enumerate ( df3 [ 'NLMO' ]): plt . annotate ( txt , ( x [ j ] + 0.1 , y [ j ] + 0.3 )) ax = gca () ax . add_patch ( FancyArrowPatch (( 0 , 0 ), ( lastX , lastY ), arrowstyle = '->' , \\ mutation_scale = 20 , color = 'red' )) for k in range ( 1 , len ( x )): ax . add_patch ( FancyArrowPatch (( x [ k ], y [ k ]), ( x [ k - 1 ], y [ k - 1 ]), arrowstyle = '<-' , \\ mutation_scale = 20 , color = 'blue' )) plt . annotate ( total_dipole , xy = ( lastX / 2 * 0.9 , lastY / 2 * 1.1 ), color = 'red' , xycoords = 'data' , textcoords = 'offset points' ) plt . annotate ( round ( diststd , 2 ), xy = ( df3 [ 'newXa' ] . min () + 1.5 , df3 [ 'newYa' ] . max () + 0.3 ), color = 'green' , xycoords = 'data' , textcoords = 'offset points' ) plt . annotate (( permlist [ i ]), # asumX, asumY, xy = ( xmin + 0.2 , ymax - 0.7 ), color = 'black' , xycoords = 'data' , textcoords = 'offset points' ) plt . annotate ( \"+\" , xy = ( cenX , cenY ), color = 'red' , xycoords = 'data' , textcoords = 'offset points' ) # plt.show() f_perm = str ( permlist [ i ]) . replace ( \"(\" , \"_\" ) f_perm = f_perm . replace ( \")\" , \"_\" ) f_perm = f_perm . replace ( \",\" , \"\" ) f_perm = f_perm . replace ( \" \" , \"\" ) pic = basename + f_perm + '.png' try : plt . savefig ( pic , ext = 'png' , format = 'png' , dpi = 100 ) except IOError : print \"Error: can \\' t find the file or read data\" Rank Quadrants STD distance ++++++++++ Rank list is : (1, 0, 3, 2) std of distances is: 1.23 ++++++++++ Rank list is : (3, 0, 2, 1) std of distances is: 1.08 ++++++++++ Rank list is : (3, 1, 2, 0) std of distances is: 1.09 ++++++++++ Rank list is : (1, 2, 3, 0) std of distances is: 1.34 ++++++++++ Rank list is : (2, 0, 1, 3) std of distances is: 1.26 ++++++++++ Rank list is : (3, 0, 1, 2) std of distances is: 1.31 ++++++++++ Rank list is : (0, 1, 3, 2) std of distances is: 1.4 ++++++++++ Rank list is : (0, 2, 1, 3) std of distances is: 1.02 ++++++++++ Rank list is : (3, 2, 1, 0) std of distances is: 1.11 ++++++++++ Rank list is : (1, 0, 2, 3) std of distances is: 1.28 ++++++++++ Rank list is : (1, 3, 2, 0) std of distances is: 1.22 ++++++++++ Rank list is : (0, 3, 2, 1) std of distances is: 1.17 ++++++++++ Rank list is : (3, 1, 0, 2) std of distances is: 1.26 ++++++++++ Rank list is : (0, 1, 2, 3) std of distances is: 1.38 ++++++++++ Rank list is : (2, 0, 3, 1) std of distances is: 1.3 ++++++++++ Rank list is : (3, 2, 0, 1) std of distances is: 1.26 ++++++++++ Rank list is : (0, 2, 3, 1) std of distances is: 1.33 ++++++++++ Rank list is : (0, 3, 1, 2) std of distances is: 1.1 ++++++++++ Rank list is : (1, 3, 0, 2) std of distances is: 1.32 ++++++++++ Rank list is : (2, 3, 0, 1) std of distances is: 1.35 ++++++++++ Rank list is : (1, 2, 0, 3) std of distances is: 1.27 ++++++++++ Rank list is : (2, 1, 0, 3) std of distances is: 1.24 ++++++++++ Rank list is : (2, 3, 1, 0) std of distances is: 1.2 ++++++++++ Rank list is : (2, 1, 3, 0) std of distances is: 1.28 In [14]: # Sort by distance stds and retrieve the first three results data = zip ( captperm , captarr ) sor = sorted ( data , key = lambda tup : tup [ 1 ]) print sor [ 0 : 3 ] [((0, 2, 1, 3), 1.0), ((3, 0, 2, 1), 1.1), ((3, 1, 2, 0), 1.1)] Inspect graphs above and note the quadrant sequence of the best looking graph. As indicated earlier, it is not the graph with lowest std value. Final Plot To make the final plot, enter the quadrant sequence of the best looking plot above (0,3,2,1) and replace the sequence in variable quad . The plot image will be saved in directory ./dipole. Enter the quadrant sequence (to line 2) and re-run the last part to get the graph. In [15]: # Enter the best sequence of quadrants quad = [ 0 , 3 , 2 , 1 ] # original sequence 0,3,2,1 or 1,3,2,0 df21 = df2 . copy () df21 [ \"xyRank\" ] = df2 . apply ( lambda row : xyrank ( row [ 'newX' ], row [ 'newY' ], \\ quad [ 0 ], quad [ 1 ], quad [ 2 ], quad [ 3 ]), axis = 1 ) # Apply function to table values in a row df21 [ \"slope\" ] = df21 . apply ( lambda row : slope ( row [ 'newX' ], row [ 'newY' ]), axis = 1 ) toprow = df21 [: 1 ] # row with zero dipole # Directly change cell rank in dataframe toprow . xyRank [ 0 ] = 4 # Isolate remaining data into rest (drop) rest1 = df21 . drop ( df21 . index [[ 0 , 0 ]]) # sort rest1 by xyRank, then by slope - descending df3 = rest1 . sort_index ( by = [ 'xyRank' , 'slope' ], ascending = [ False , False ]) # Put it back df3 = pd . concat ([ toprow , df3 ]) . reset_index () . ix [::] df3 = df3 . sort_index ( by = [ 'xyRank' , 'slope' ], ascending = [ False , False ]) # Translate coordinates from xyz=0,0,0 df3 [ 'newXa' ] = df3 . newX . cumsum () df3 [ 'newYa' ] = df3 . newY . cumsum () # print df3 # works OK # Calculate total dipole lastX = df3 . tail ( 1 ) . newXa # row and value lastX = lastX . tolist ()[ 0 ] # value only lastY = df3 . tail ( 1 ) . newYa lastY = lastY . tolist ()[ 0 ] total_dipole = sqrt ( np . power ( lastX , 2 ) + np . power ( lastY , 2 )) total_dipole = round ( total_dipole , 2 ) # Calc distances of x,y and assess fit to a circle cenX = df3 [ 'newXa' ] . mean () cenY = df3 [ 'newYa' ] . mean () distX = abs ( cenX - df3 . newXa ) distY = abs ( cenY - df3 . newYa ) # distance from centroid distXY = np . sqrt ( distX * distX + distY * distY ) diststd = distXY . std () x = df3 . newXa y = df3 . newYa # Set rectangular plot dimensions to keep lengths proportional xlow = x . min () xhigh = x . max () ylow = y . min () yhigh = y . max () def lst_sort ( list ): ''' Sort list of floats by values. :type list: list of floats :param list: max and min x,y-coordinates :rtype: list of floats :return: sorted list of floats ''' abslist = [] for item in list : abslist . append ( item ) return sorted ( abslist ) margins = lst_sort ([ xlow , ylow , xhigh , yhigh ]) # Plot plt . figure () # To generate multiple distinct plots. plt . suptitle ( 'Dipole Moments (D)' ) ax = [] xmin = margins [ 0 ] - 1 xmax = margins [ 3 ] + 1 ymin = margins [ 0 ] - 1 ymax = margins [ 3 ] + 1 plt . ylabel ( 'Y' ) plt . xlabel ( 'X' ) plt . grid ( True ) plt . xlim ( xmin , xmax ) plt . ylim ( ymin , ymax ) color = 'blue' plt . scatter ( df3 . newXa , df3 . newYa , s = 80 , c = color , label = 'NLMOs' ) # plt.plot(df3.newXa, df3.newYa, c=color) # plt.legend(loc=1,borderaxespad=0.) for j , txt in enumerate ( df3 [ 'NLMO' ]): plt . annotate ( txt , ( x [ j ] + 0.1 , y [ j ] + 0.3 )) ax = gca () ax . add_patch ( FancyArrowPatch (( 0 , 0 ),( lastX , lastY ), arrowstyle = '->' , mutation_scale = 20 , \\ color = 'red' )) for k in range ( 1 , len ( x )): ax . add_patch ( FancyArrowPatch (( x [ k ], y [ k ]),( x [ k - 1 ], y [ k - 1 ]), arrowstyle = '<-' , \\ mutation_scale = 20 , color = 'blue' )) plt . annotate ( total_dipole , xy = ( lastX / 2 * 0.9 , lastY / 2 * 1.1 ), color = 'red' , xycoords = 'data' , textcoords = 'offset points' ) plt . annotate (( quad ), # asumX, asumY, xy = ( xmin + 0.4 , ymax - 0.6 ), color = 'black' , xycoords = 'data' , textcoords = 'offset points' ) plt . annotate ( \"+\" , xy = ( cenX , cenY ), color = 'red' , xycoords = 'data' , textcoords = 'offset points' ) df3 . drop ( 'level_0' , axis = 1 , inplace = True ) df3 . drop ( 'index' , axis = 1 , inplace = True ) HTML ( df3 . to_html ( classes = 'grid' , escape = False )) Out[15]: NLMO Type X Y Z Tot_Dip newX newY xyRank slope newXa newYa 0 0 0.00 0 0.00 0.00 0.00 0.00 4 0.000000 0.00 0.00 1 12 BD ( 1) C 2- H 6 1.72 0 -0.58 1.82 1.72 -0.58 3 -0.337209 1.72 -0.58 2 4 LP ( 1) N 1 -0.20 0 -1.64 1.65 -0.20 -1.64 2 8.200000 1.52 -2.22 3 10 BD ( 1) C 2- O 3 -1.90 0 -1.44 2.38 -1.90 -1.44 2 0.757895 -0.38 -3.66 4 5 LP ( 1) O 3 -2.37 0 -1.64 2.88 -2.37 -1.64 2 0.691983 -2.75 -5.30 5 11 BD ( 2) C 2- O 3 -0.67 0 -0.46 0.81 -0.67 -0.46 2 0.686567 -3.42 -5.76 6 8 BD ( 1) N 1- H 4 -0.68 0 0.47 0.82 -0.68 0.47 1 -0.691176 -4.10 -5.29 7 7 BD ( 1) N 1- C 2 0.02 0 0.85 0.85 0.02 0.85 0 42.500000 -4.08 -4.44 8 6 LP ( 2) O 3 0.89 0 0.75 1.16 0.89 0.75 0 0.842697 -3.19 -3.69 9 9 BD ( 1) N 1- H 5 0.75 0 0.46 0.88 0.75 0.46 0 0.613333 -2.44 -3.23 An alternative and acceptable vector decomposition is shown in Figure 4 . Figure 4 Alternative vector decomposition. This concludes the analysis of NLMO dipole moment data from the NBO output file. Several vector paths composed of partial formamide dipoles were created and saved as images. Next step will be analysis of partial NLMO dipoles in terms of bonds and lone pair contributions. The complete Notebook Dipoles_quad_all_Jupyter.ipynb and accompanying files are available at the GitHub .","tags":"NBO","url":"https://marpat.github.io/Natural-Dipole-Analysis.html","loc":"https://marpat.github.io/Natural-Dipole-Analysis.html"}]};